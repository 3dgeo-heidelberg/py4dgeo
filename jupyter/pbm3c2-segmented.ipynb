{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Correspondence-driven plane-based M3C2 (PBM3C2) with known segmentation\n",
    "\n",
    "<p style=\"color:red;\"> <a style=\"font-weight: bold\">\n",
    "WARNING:</a> The implementation of this method is experimental and under active development.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "In this notebook, we are extending the [PB-M3C2 implementation](pbm3c2.ipynb) to work with segmentation information that is already present in the input data. This is useful if you are embedding the calculation into a larger workflow where a segmentation has already been produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py4dgeo\n",
    "import pooch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "py4dgeo.set_interactive_backend(\"vtk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "We are reading the two input epochs from XYZ files which contain a total of four columns: X, Y and Z coordinates, as well a segment ID mapping each point to a segment. The `read_from_xyz` functionality allows us to read additional data columns through its `additional_dimensions` parameter. It is expecting a dictionary that maps the column index to a column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pooch to download data from Zenodo\n",
    "p = pooch.Pooch(base_url=\"doi:10.5281/zenodo.16751963/\", path=pooch.os_cache(\"py4dgeo\"))\n",
    "p.load_registry_from_doi()\n",
    "\n",
    "try:\n",
    "    # Download and extract the dataset\n",
    "    p.fetch(\"usage_data.zip\", processor=pooch.Unzip(members=[\"usage_data\"]))\n",
    "    \n",
    "    # Define path to the extracted data\n",
    "    data_path = p.path / \"usage_data.zip.unzip\" / \"usage_data\"\n",
    "    print(f\"Data path: {data_path}\")\n",
    "    \n",
    "    # Read XYZ files from the extracted directory\n",
    "    epoch0, epoch1 = py4dgeo.read_from_xyz(\n",
    "        data_path / \"plane_horizontal_t1_segmented.xyz\", \n",
    "        data_path / \"plane_horizontal_t2_segmented.xyz\",\n",
    "        additional_dimensions={3: \"segment_id\"},\n",
    "        delimiter=\",\",\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Failed to download or extract data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Again, we instantiate the algorithm. Due to fundamental differences in the algorithm workflow, we are using a separated algorithm class for this use case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = py4dgeo.PBM3C2WithSegments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Next, we will read the segmented point cloud, which is part of the input epochs, and reconstruct the required segments from it. As a result, we get the same information that we got from the `export_segments_for_labelling` method in the [base PB-M3C2 implementation](pbm3c2.ipynb). Again, we need to provide labelling and can choose to do so either interactively or with external tools. In contrast to `export_segments_for_labelling`, `reconstruct_post_segmentation_output` only writes one file - the full segmentation information file (which defaults to `extracted_segments.seg`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_epoch0, xyz_epoch1, segments = alg.reconstruct_post_segmentation_output(\n",
    "    epoch0=epoch0,\n",
    "    epoch1=epoch1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Having completed the labelling process, we read it back in and start the trainging procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg.training(\n",
    "    extracted_segments_file_name=str(data_path / \"extracted_segments.seg\"),\n",
    "    extended_y_file_name=\"testdata-labelling2.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, uncertainties = alg.compute_distances(epoch0, epoch1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "*Note*: When comparing distance results between this notebook and the [base algorithm notebook](pbm3c2.ipynb), you might notice, that results do not necessarily agree even if the given segmentation information is exactly the same as the one computed in the base algorithm. This is due to the reconstruction process in this algorithm being forced to select the segment position (exported as the *core point*) from the segment points instead of reconstructing the correct position from the base algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p4dgeo-doc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
