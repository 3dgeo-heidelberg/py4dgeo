{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This notebook explains how to use the extraction- and merge-function of the py4dgeo-packag. The extraction-function extracts 4D-objects-by-change automatically from a point-cloud, by using either the Ramer-Douglas-Peucker-algorithm (RDP) or a Decision-Tree-Regressor (DTR). ",
   "id": "1254540a0ffe8e83"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As a first step, we simply import the py4dgeo package:",
   "id": "5cc71dc1ce138c13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import py4dgeo\n",
    "from py4dgeo import *"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To perform the extraction, we need a Spatiotemporal-Analysis-object which includes corepoints, M3C2-distances, level of detection and time-stamps for correspoinding epochs. The object can then be loaded like this:",
   "id": "944434baea33e67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "analysis = py4dgeo.SpatiotemporalAnalysis('jupyter/riverbank_4dobc_test.zip', force = False)",
   "id": "ab0d88767a462e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can then use the extract-function, to extract the 4D-objects-by-change of the dataset. It is possible, to tweak some of the parameters to preference. With the first parameter, one can decide which method to use. The Decision-Tree-Regressor can be selected with 'DTR', the Ramer-Douglas-Peucker-algorithm with 'RDP'. The second parameter lets the user adjust the size of the smoothing window. The third parameter subsamples the dataset, to make the process faster. The default value is 1. With the forth parameter, the user can adjust the maximum number of epochs, that the algorithm takes into account, to determine if the 4D-obc passed the magnitude threshold or not. The last parameter is optional, and lets the user include a period of time, in which a datagap happened, so that the alogrithm can take this into account.  ",
   "id": "c5d6a49e378afbcd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "analysis.extract('RDP', 5, 1000, 200, 828)",
   "id": "7d5a3a586d056ab2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Another function that is to be expalined in this notebook is the merge-function, which tackles the problem of oversegementation, by merging 4D-obcs that are similar to one another. This function can be used, using the following line.",
   "id": "58eb5a9f2bc55a50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "merged = analysis.merge(time_threshold=0.7, spatial_threshold=0.1)",
   "id": "8d8c34b7fff00199"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "With time_threshold and spatial_threshold, the user can adjust to which degree of similarity objects should be merged. These values can be any number between 0 and 1, with 0 meaning no temporal or spatial overlap, and 1 meaning a complete overlap",
   "id": "244681e2b0142677"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After being run, it is possible to visualize the merged objects, by using the following line. ",
   "id": "cf079a06023fd0a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "merged[0].plot()",
   "id": "c4b21b5834fc6478"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
