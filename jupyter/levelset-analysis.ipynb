{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py4dgeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = py4dgeo.SpatiotemporalAnalysis(\"synthetic.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.invalidate_results(seeds=False, objects=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Options for the data setup:\n",
    "- `first_timestep` (int): The first timestep to process. Default is 0.\n",
    "- `last_timestep` (int): The last timestep to process. If set to -1, all timesteps until the end are processed. Default is -1.\n",
    "- `timestep_interval` (int): The interval between timesteps to process. Default is 1.\n",
    "\n",
    "Example for the interval pairings:\n",
    "interval: 24 (every timestep will be compared to the timestep + 24)\n",
    "first_timestep: 0 (start with the 0 index)\n",
    "last_timestep: 75 (last index to be used will be 75, so the highest index accessed will be 99)\n",
    "step0: f1:0 f2:24\n",
    "step1: f1:1 f2:25\n",
    "step2: f1:2 f2:26\n",
    "step3: f3:3 f2:27\n",
    "...\n",
    "stepN f1:75 f2:99\n",
    "\n",
    "Options for level set algorithm:\n",
    "- `reuse_intermediate` (bool): Re-use intermediate calculations\n",
    "(neighbors, normals, tangents). Default is True.\n",
    "- `active_contour_model` (str): Active contours model, either\n",
    "'chan_vese' or 'lmv' (Local Mean and Variance). Default is 'chan_vese'.\n",
    "- `num_cycles` (int): Number of cycles, each runs a number of steps\n",
    "then stores a result. Default is 12.\n",
    "- `num_steps` (int): Number of steps per cycle. Default is 50.\n",
    "- `num_smooth` (int): Number of smoothing passes for zeta.\n",
    "Default is 1.\n",
    "- `stepsize` (int): Explicit Euler step size. Default is 1000.\n",
    "- `nu` (float): Controls regularization. Default is 0.0001.\n",
    "- `mu` (float): Controls curvature. Default is 0.0025.\n",
    "- `lambda1` (float): Controls zeta-in term. Default is 1.0.\n",
    "- `lambda2` (float): Controls zeta-out term. Default is 1.0.\n",
    "- `epsilon` (float): Heaviside/delta approximation \"width\",\n",
    "is scaled with `h`. Default is 1.0.\n",
    "- `h` (float): Approximate neighborhood radius\n",
    "(all k neighbors should be within). Default is 2.5.\n",
    "- `k` (int): Number of kNN neighbors. Default is 7.\n",
    "- `tolerance` (float): Termination tolerance. Default is 5e-5.\n",
    "- `cue_clip_pc` (float): Robust cues, clip at X%. Default is 99.9.\n",
    "- `vox_size` (int): Initialization voxel size. Default is 10.\n",
    "- `init_pc` (int): Initialization cue percentage. Default is 50.\n",
    "- `init_method` (str): Initialization method, either 'voxel' or 'cue'.\n",
    "Default is 'voxel'.\n",
    "- `extraction_threshold` (int): Neighbor threshold for points\n",
    "to be extracted\n",
    "(must have >= salient neighbors to be extracted).\n",
    "Calculated as `k // 2`.\n",
    "- `center_data` (bool): Recenter cues by subtracting cue median.\n",
    "Default is False.\n",
    "\n",
    "\n",
    "Options for the shape analysis:\n",
    "- `_filter` (str): Choose between the positiv and negativ data files.\n",
    "Default is 'positiv'.\n",
    "- `distance_threshold` (float): How far points can be to still be\n",
    "considered of the same object. Default is 1.\n",
    "- `change_threshold` (float): How high the change value needs to be to\n",
    "be considered a valid entry. Default is 0.5.\n",
    "- `alpha` (float): Alpha parameter for the alpha shape identification,\n",
    "the lower the smoother the shape, but less exact. Default is 1.\n",
    "- `area_threshhold` (int): Area threshold for filtering small polygons.\n",
    "Default is 100.\n",
    "- `iou_threshold` (float): Intersection over Union (IoU) threshold for\n",
    "assigning objects IDs in different time steps. Default is 0.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = py4dgeo.LevelSetAlgorithm(\n",
    "    first_timestep=0,\n",
    "    last_timestep=4,\n",
    "    timestep_interval=10,\n",
    "    alpha=0.1,\n",
    "    iou_threshold=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.run(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = analysis.objects\n",
    "objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import graph_objects as go\n",
    "\n",
    "combined_figure = go.Figure()\n",
    "for object in objects:\n",
    "    fig = object.plot()\n",
    "    combined_figure.add_traces(fig.data)\n",
    "\n",
    "combined_figure.update_layout(\n",
    "    title_text=\"Plot of Polygons\", scene=dict(aspectmode=\"cube\"), height=500, width=500\n",
    ")\n",
    "combined_figure.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
