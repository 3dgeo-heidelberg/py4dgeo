{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Correspondence-driven plane-based M3C2 (PBM3C2) with pre-segmented planes\n",
    "Implemented in: py4dgeo.pbm3c2\n",
    "\n",
    "\n",
    "**Related publication**\n",
    "Zahs, V., Winiwarter, L., Anders, K., Williams, J.G., Rutzinger, M. & Höfle, B. (2022): Correspondence-driven plane-based M3C2 for lower uncertainty in 3D topographic change quantification. ISPRS Journal of Photogrammetry and Remote Sensing, 183, pp. 541-559. DOI: [10.1016/j.isprsjprs.2021.11.018](https://doi.org/10.1016/j.isprsjprs.2021.11.018)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## **Method description**\n",
    "In this notebook, we present how the *Correspondence-driven plane-based M3C2* (PB-M3C2, [Zahs et al., 2022] algorithm for point cloud distance computation using the `py4dgeo` package.\n",
    "\n",
    "The concept and method of PBM3C2 are explained in this scientific talk:\n",
    "\n",
    "<a href=\"https://youtu.be/5pjkpajsRNU\" target=\"_blank\"><img src=\"https://github.com/3dgeo-heidelberg/py4dgeo/blob/main/doc/img/thumb_youtube_zahs_isprs2022.png?raw=true\" alt=\"\" width=\"400\" /></a>\n",
    "\n",
    "In the current implementation of PBM3C2, a plane segmentation outside py4dgeo (e.g., using CloudCompare or other tools) is required. As PB-M3C2 is a learning algorithm, it requires user-labelled input data in the process, which can be created in graphical software, such as CloudCompare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T06:38:56.185539300Z",
     "start_time": "2025-10-21T06:38:24.973096500Z"
    }
   },
   "outputs": [],
   "source": [
    "import py4dgeo\n",
    "import numpy as np\n",
    "import pooch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "In this notebook, we use a dataset of synthetic planes, which is downloaded from the py4dgeo data repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T06:39:54.457678300Z",
     "start_time": "2025-10-21T06:39:52.995088100Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Archive with doi:10.5281/zenodo.16751963 not found (see https://doi.org/10.5281/zenodo.16751963). Is the DOI correct?",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m p = pooch.Pooch(base_url=\u001B[33m\"\u001B[39m\u001B[33mdoi:10.5281/zenodo.16751963/\u001B[39m\u001B[33m\"\u001B[39m, path=pooch.os_cache(\u001B[33m\"\u001B[39m\u001B[33mpy4dgeo\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload_registry_from_doi\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m      5\u001B[39m     \u001B[38;5;66;03m# Download and extract the dataset\u001B[39;00m\n\u001B[32m      6\u001B[39m     p.fetch(\u001B[33m\"\u001B[39m\u001B[33mpbm3c2.zip\u001B[39m\u001B[33m\"\u001B[39m, processor=pooch.Unzip(members=[\u001B[33m\"\u001B[39m\u001B[33mpbm3c2\u001B[39m\u001B[33m\"\u001B[39m]))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pbm3c2\\Lib\\site-packages\\pooch\\core.py:701\u001B[39m, in \u001B[36mPooch.load_registry_from_doi\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    699\u001B[39m \u001B[38;5;66;03m# Create a repository instance\u001B[39;00m\n\u001B[32m    700\u001B[39m doi = \u001B[38;5;28mself\u001B[39m.base_url.replace(\u001B[33m\"\u001B[39m\u001B[33mdoi:\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m701\u001B[39m repository = \u001B[43mdoi_to_repository\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    703\u001B[39m \u001B[38;5;66;03m# Call registry population for this repository\u001B[39;00m\n\u001B[32m    704\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m repository.populate_registry(\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pbm3c2\\Lib\\site-packages\\pooch\\downloaders.py:689\u001B[39m, in \u001B[36mdoi_to_repository\u001B[39m\u001B[34m(doi)\u001B[39m\n\u001B[32m    682\u001B[39m repositories = [\n\u001B[32m    683\u001B[39m     FigshareRepository,\n\u001B[32m    684\u001B[39m     ZenodoRepository,\n\u001B[32m    685\u001B[39m     DataverseRepository,\n\u001B[32m    686\u001B[39m ]\n\u001B[32m    688\u001B[39m \u001B[38;5;66;03m# Extract the DOI and the repository information\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m689\u001B[39m archive_url = \u001B[43mdoi_to_url\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    691\u001B[39m \u001B[38;5;66;03m# Try the converters one by one until one of them returned a URL\u001B[39;00m\n\u001B[32m    692\u001B[39m data_repository = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.conda\\envs\\pbm3c2\\Lib\\site-packages\\pooch\\downloaders.py:652\u001B[39m, in \u001B[36mdoi_to_url\u001B[39m\u001B[34m(doi)\u001B[39m\n\u001B[32m    650\u001B[39m url = response.url\n\u001B[32m    651\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[32m400\u001B[39m <= response.status_code < \u001B[32m600\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m652\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    653\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mArchive with doi:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdoi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m not found (see \u001B[39m\u001B[38;5;132;01m{\u001B[39;00murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m). Is the DOI correct?\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    654\u001B[39m     )\n\u001B[32m    655\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m url\n",
      "\u001B[31mValueError\u001B[39m: Archive with doi:10.5281/zenodo.16751963 not found (see https://doi.org/10.5281/zenodo.16751963). Is the DOI correct?"
     ]
    }
   ],
   "source": [
    "p = pooch.Pooch(base_url=\"doi:10.5281/zenodo.16751963/\", path=pooch.os_cache(\"py4dgeo\"))\n",
    "p.load_registry_from_doi()\n",
    "\n",
    "try:\n",
    "    # Download and extract the dataset\n",
    "    p.fetch(\"pbm3c2.zip\", processor=pooch.Unzip(members=[\"pbm3c2\"]))\n",
    "\n",
    "    # Define path to the extracted data\n",
    "    data_path = p.path / \"pbm3c2.zip.unzip\" / \"pbm3c2\"\n",
    "    print(f\"Data path: {data_path}\")\n",
    "\n",
    "    # Read XYZ files from the extracted directory\n",
    "    epoch0_path = str(data_path / \"epoch0.xyz\")\n",
    "    epoch1_path = str(data_path / \"epoch1.xyz\")\n",
    "    training_segments_path = str(data_path / \"epoch_extended_y.csv\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to download or extract data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "We are reading the two input epochs from XYZ files which contain a total of four columns: X, Y and Z coordinates, as well a segment ID mapping each point to a plane and normal vector components in X, Y and Z. The `read_from_xyz` functionality allows us to read additional data columns through its `additional_dimensions` parameter. It is expecting a dictionary that maps the column index to a column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T06:35:17.842693100Z",
     "start_time": "2025-10-21T06:35:17.833684900Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch0 = py4dgeo.epoch.read_from_xyz(\n",
    "    epoch0_path,\n",
    "    additional_dimensions={3: \"segment_id\", 4: \"N_x\", 5: \"N_y\", 6: \"N_z\"},\n",
    "    delimiter=\" \",\n",
    ")\n",
    "epoch1 = py4dgeo.epoch.read_from_xyz(\n",
    "    epoch1_path,\n",
    "    additional_dimensions={3: \"segment_id\", 4: \"N_x\", 5: \"N_y\", 6: \"N_z\"},\n",
    "    delimiter=\" \",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "The point cloud data we use here consists of 100 planar segments, with 70 used for training and 30 for application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-10-21T06:35:17.839691200Z"
    }
   },
   "outputs": [],
   "source": [
    "n_planes = 100\n",
    "n_train = int(0.7 * n_planes)\n",
    "train_ids = np.arange(n_train)\n",
    "apply_ids = np.arange(n_train, n_planes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We instantiate an instance of the algorithm class. Here, you can set the registration error for the input point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T06:35:17.868790400Z",
     "start_time": "2025-10-21T06:35:17.851685Z"
    }
   },
   "outputs": [],
   "source": [
    "alg = py4dgeo.PBM3C2(reg_error=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "The algorithm requires the user to provide a labeled training dataset **correspondences_file** to learn how to match the segments. This csv file contains three columns: the first two are the plane segment_id from epoch 1 and epoch 2, and the third is a label (1 for a correct match, 0 for an incorrect one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-10-21T06:35:17.853687600Z"
    }
   },
   "outputs": [],
   "source": [
    "correspondences_df = alg.compute(\n",
    "    epoch0=epoch0,\n",
    "    epoch1=epoch1,\n",
    "    correspondences_file=training_segments_path,\n",
    "    apply_ids=apply_ids,\n",
    "    search_radius=5.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-10-21T06:35:17.856785700Z"
    }
   },
   "outputs": [],
   "source": [
    "print(correspondences_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-10-21T06:35:17.860780400Z"
    }
   },
   "outputs": [],
   "source": [
    "distances = correspondences_df[\"distance\"]\n",
    "uncertainties = correspondences_df[\"uncertainty\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## References\n",
    "* Zahs, V., Winiwarter, L., Anders, K., Williams, J.G., Rutzinger, M. & Höfle, B. (2022): Correspondence-driven plane-based M3C2 for lower uncertainty in 3D topographic change quantification. ISPRS Journal of Photogrammetry and Remote Sensing, 183, pp. 541-559. DOI: [10.1016/j.isprsjprs.2021.11.018](https://doi.org/10.1016/j.isprsjprs.2021.11.018)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p4dgeo-doc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
