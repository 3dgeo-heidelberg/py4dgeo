{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import py4dgeo\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "py4dgeo.set_interactive_backend(\"vtk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Function to create synthetic test epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def random_rotation_matrix():\n",
    "    \"\"\"Generate a random 3×3 rotation matrix using QR decomposition.\"\"\"\n",
    "    H = np.random.randn(3, 3)\n",
    "    Q, R = np.linalg.qr(H)\n",
    "    # Ensure right-handed orientation\n",
    "    if np.linalg.det(Q) < 0:\n",
    "        Q[:, 0] = -Q[:, 0]\n",
    "    return Q\n",
    "\n",
    "def write_las(outpoints, outfilepath, normals=None, segment_id=None, attribute_dict={}):\n",
    "    import laspy\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"\n",
    "    Write LAS/LAZ file with coords, optional normals, and extra attributes.\n",
    "    \"\"\"\n",
    "\n",
    "    hdr = laspy.LasHeader(version=\"1.4\", point_format=6)\n",
    "    las = laspy.LasData(hdr)\n",
    "\n",
    "    # coords\n",
    "    las.x = outpoints[:, 0]\n",
    "    las.y = outpoints[:, 1]\n",
    "    las.z = outpoints[:, 2]\n",
    "\n",
    "    # normals (as defined by common LAS ExtraBytes convention)\n",
    "    if normals is not None:\n",
    "        normals = np.asarray(normals, dtype=np.float32)\n",
    "        if normals.shape[1] != 3:\n",
    "            raise ValueError(\"Normals must have shape (N,3)\")\n",
    "        for i, comp in enumerate([\"NX\", \"NY\", \"NZ\"]):\n",
    "            las.add_extra_dim(laspy.ExtraBytesParams(name=comp, type=np.float32))\n",
    "            las[comp] = normals[:, i]\n",
    "\n",
    "    # segment_id into point_source_id\n",
    "    if segment_id is not None:\n",
    "        seg = np.asarray(segment_id, dtype=np.uint32)\n",
    "        if seg.max() > 65535:\n",
    "            raise ValueError(\"LAS point_source_id supports only 0–65535\")\n",
    "        las.point_source_id = seg.astype(np.uint16)\n",
    "\n",
    "    # other attributes\n",
    "    for key, vals in attribute_dict.items():\n",
    "        vals = np.asarray(vals)\n",
    "        if key in las.point_format.dimension_names:\n",
    "            las[key] = vals\n",
    "        else:\n",
    "            dtype = np.float32 if np.issubdtype(vals.dtype, np.floating) else np.int32\n",
    "            las.add_extra_dim(laspy.ExtraBytesParams(name=key, type=dtype))\n",
    "            las[key] = vals.astype(dtype)\n",
    "\n",
    "    las.write(outfilepath)\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def make_test_epochs(n_planes=5,\n",
    "                     points_per_side=20,\n",
    "                     shift=(0.5, -0.5, 0.5),\n",
    "                     noise=0.0,\n",
    "                     file_prefix=\"epoch\",\n",
    "                     unambiguous=True):\n",
    "    \"\"\"\n",
    "    Create two synthetic Epochs with randomly rotated planes.\n",
    "\n",
    "    unambiguous=True is a paramter to determine whether segment IDs across all epochs should be unique (True) or if segment IDs start at 0 for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    xyz0_list, xyz1_list = [], []\n",
    "    seg0_list, seg1_list = [], []\n",
    "    normals0_list, normals1_list = [], []\n",
    "\n",
    "    for i in range(n_planes):\n",
    "        # start with a default normal\n",
    "        n = np.array([0.0, 0.0, 1.0])\n",
    "\n",
    "        # build orthonormal basis\n",
    "        u = np.array([1.0, 0.0, 0.0])\n",
    "        v = np.cross(n, u)\n",
    "\n",
    "        # stack basis and rotate\n",
    "        basis = np.column_stack([u, v, n])  # (3,3)\n",
    "        R = random_rotation_matrix()\n",
    "        u_rot, v_rot, n_rot = R @ basis\n",
    "\n",
    "        # grid of points\n",
    "        grid = np.linspace(-1, 1, points_per_side)\n",
    "        uu, vv = np.meshgrid(grid, grid)\n",
    "        pts = uu[..., None] * u_rot + vv[..., None] * v_rot + 5 * i * n_rot\n",
    "        pts = pts.reshape(-1, 3)\n",
    "\n",
    "        # noise (isotropic jitter)\n",
    "        if noise > 0:\n",
    "            pts += np.random.normal(scale=noise, size=pts.shape)\n",
    "\n",
    "        # always add tiny thickness along normal to avoid PCA degeneracy\n",
    "        pts += np.random.normal(scale=1e-6, size=(pts.shape[0], 1)) * n_rot\n",
    "\n",
    "        pts_shift = pts + np.array(shift, dtype=float)\n",
    "\n",
    "        xyz0_list.append(pts)\n",
    "        xyz1_list.append(pts_shift)\n",
    "        seg0_list.append(np.full(pts.shape[0], i, dtype=np.int64))\n",
    "        if unambiguous == True:\n",
    "            seg1_list.append(np.full(pts.shape[0], i + n_planes, dtype=np.int64))\n",
    "        else:\n",
    "            seg1_list.append(np.full(pts.shape[0], i, dtype=np.int64))\n",
    "        normals0_list.append(np.tile(n_rot, (pts.shape[0], 1)))\n",
    "        normals1_list.append(np.tile(n_rot, (pts.shape[0], 1)))\n",
    "\n",
    "    # Concatenate\n",
    "    xyz0, xyz1 = np.vstack(xyz0_list), np.vstack(xyz1_list)\n",
    "    seg0, seg1 = np.concatenate(seg0_list), np.concatenate(seg1_list)\n",
    "    normals0, normals1 = np.vstack(normals0_list), np.vstack(normals1_list)\n",
    "\n",
    "    # Structured arrays\n",
    "    dtype = [\n",
    "        (\"segment_id\", np.int64),\n",
    "        (\"N_x\", np.float64),\n",
    "        (\"N_y\", np.float64),\n",
    "        (\"N_z\", np.float64),\n",
    "    ]\n",
    "    add0 = np.zeros(xyz0.shape[0], dtype=dtype)\n",
    "    add0[\"segment_id\"], add0[\"N_x\"], add0[\"N_y\"], add0[\"N_z\"] = seg0, normals0[:, 0], normals0[:, 1], normals0[:, 2]\n",
    "    add1 = np.zeros(xyz1.shape[0], dtype=dtype)\n",
    "    add1[\"segment_id\"], add1[\"N_x\"], add1[\"N_y\"], add1[\"N_z\"] = seg1, normals1[:, 0], normals1[:, 1], normals1[:, 2]\n",
    "\n",
    "    epoch0 = py4dgeo.Epoch(xyz0, additional_dimensions=add0)\n",
    "    epoch1 = py4dgeo.Epoch(xyz1, additional_dimensions=add1)\n",
    "\n",
    "    # Save epochs to .xyz (7 space-separated columns)\n",
    "    data0 = np.column_stack([xyz0, seg0.reshape(-1, 1), normals0])\n",
    "    data1 = np.column_stack([xyz1, seg1.reshape(-1, 1), normals1])\n",
    "    np.savetxt(f\"{file_prefix}0.xyz\", data0, delimiter=\" \", fmt=\"%.6f\")\n",
    "    np.savetxt(f\"{file_prefix}1.xyz\", data1, delimiter=\" \", fmt=\"%.6f\")\n",
    "\n",
    "    # Save epochs to .las\n",
    "    write_las(xyz0,f\"{file_prefix}0.las\", normals=normals0,segment_id=seg0)\n",
    "    write_las(xyz1,f\"{file_prefix}1.las\", normals=normals1,segment_id=seg1)\n",
    "\n",
    "    # Save extended_y.csv with known correspondences\n",
    "    # Format: epoch0_segment_id, epoch1_segment_id, label\n",
    "\n",
    "    n_train = max(1, int(0.7 * n_planes))   # 10% of planes, at least 1\n",
    "\n",
    "    train_ids = np.arange(n_train)          # first 10% → training\n",
    "    apply_ids = np.arange(n_train, n_planes)  # rest → left for application\n",
    "\n",
    "    # positives for training\n",
    "    positives = [[i, i + n_planes, 1] for i in train_ids]\n",
    "\n",
    "    # negatives for training (simple wrong matches)\n",
    "    negatives = []\n",
    "    for i in train_ids:\n",
    "        wrong_j = (i + 1) % n_planes\n",
    "        if wrong_j in train_ids:   # keep negatives inside training subset\n",
    "            negatives.append([i, wrong_j + n_planes, 0])\n",
    "\n",
    "    correspondences = np.array(positives + negatives, dtype=int)\n",
    "\n",
    "    np.savetxt(f\"{file_prefix}_extended_y.csv\", correspondences, delimiter=\",\", fmt=\"%d\")\n",
    "\n",
    "    print(f\"Training correspondences saved for {len(train_ids)} planes.\")\n",
    "    print(f\"Remaining {len(apply_ids)} planes reserved for application/testing.\")\n",
    "\n",
    "    print(f\"Saved {file_prefix}0.xyz, {file_prefix}1.xyz and {file_prefix}_extended_y.csv\")\n",
    "\n",
    "    return epoch0, epoch1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic test data\n",
    "epoch0_synth, epoch1_synth = make_test_epochs(n_planes=100, shift=(0.3, -0.2, 0.1), noise=0.01,unambiguous=True)\n",
    "print(\"Epoch0 points:\", epoch0_synth.cloud.shape)\n",
    "print(\"Epoch1 points:\", epoch1_synth.cloud.shape)\n",
    "print(\"Epoch0 unique IDs:\", np.unique(epoch0_synth.additional_dimensions[\"segment_id\"]))\n",
    "print(\"Epoch1 unique IDs:\", np.unique(epoch1_synth.additional_dimensions[\"segment_id\"]))\n",
    "\n",
    "# plot the synthetic data\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# flatten (N,1) → (N,)\n",
    "seg0 = epoch0_synth.additional_dimensions['segment_id'].ravel()\n",
    "seg1 = epoch1_synth.additional_dimensions['segment_id'].ravel()\n",
    "\n",
    "all_ids = np.unique(np.concatenate([seg0, seg1]))\n",
    "n_ids = len(all_ids)\n",
    "\n",
    "# discrete colormap with n_ids colors\n",
    "cmap = plt.get_cmap(\"tab20\", n_ids)\n",
    "\n",
    "sc0 = ax.scatter(epoch0_synth.cloud[:,0],\n",
    "                 epoch0_synth.cloud[:,1],\n",
    "                 epoch0_synth.cloud[:,2],\n",
    "                 c=seg0, cmap=cmap,\n",
    "                 marker=\"o\", alpha=0.6, label=\"Epoch0\")\n",
    "\n",
    "sc1 = ax.scatter(epoch1_synth.cloud[:,0],\n",
    "                 epoch1_synth.cloud[:,1],\n",
    "                 epoch1_synth.cloud[:,2],\n",
    "                 c=seg1, cmap=cmap,\n",
    "                 marker=\"x\", alpha=0.6, label=\"Epoch1\")\n",
    "\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "ax.set_title(\"Synthetic planes with unique segment IDs\")\n",
    "\n",
    "# Colorbar with ticks at actual IDs\n",
    "cbar = fig.colorbar(sc1, ax=ax, shrink=0.6, ticks=all_ids)\n",
    "cbar.set_label(\"Segment ID\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch0 = py4dgeo.epoch.read_from_xyz(\n",
    "    'epoch0.xyz',\n",
    "    additional_dimensions={3: \"segment_id\", 4: \"N_x\", 5: \"N_y\", 6: \"N_z\"},\n",
    "    delimiter=\" \"\n",
    ")\n",
    "epoch1 = py4dgeo.epoch.read_from_xyz(\n",
    "    'epoch1.xyz',\n",
    "    additional_dimensions={3: \"segment_id\", 4: \"N_x\", 5: \"N_y\", 6: \"N_z\"},\n",
    "    delimiter=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.genfromtxt(\"epoch0.xyz\", delimiter=\" \")\n",
    "seg_ids, counts = np.unique(data[:,3], return_counts=True)\n",
    "print(\"Segment IDs:\", seg_ids)\n",
    "print(\"Counts per segment:\", counts)\n",
    "print(\"Any empty segment?\", np.any(counts == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "TESTING BLOCKS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg0 = epoch0.additional_dimensions[\"segment_id\"].ravel()\n",
    "print(\"Epoch0 segments and counts:\", np.unique(seg0, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Test of pbm3c2_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch0 = py4dgeo.epoch.read_from_xyz(\n",
    "    'epoch0.xyz',\n",
    "    additional_dimensions={3: \"segment_id\", 4: \"N_x\", 5: \"N_y\", 6: \"N_z\"},\n",
    "    delimiter=\" \"\n",
    ")\n",
    "epoch1 = py4dgeo.epoch.read_from_xyz(\n",
    "    'epoch1.xyz',\n",
    "    additional_dimensions={3: \"segment_id\", 4: \"N_x\", 5: \"N_y\", 6: \"N_z\"},\n",
    "    delimiter=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pbm3c2_test import PBM3C2\n",
    "import numpy as np\n",
    "\n",
    "n_planes = 100\n",
    "n_train = int(0.7 * n_planes)\n",
    "train_ids = np.arange(n_train)\n",
    "apply_ids = np.arange(n_train, n_planes) #70-99\n",
    "\n",
    "pbm3c2_algorithm = PBM3C2(reg_error=0.01)\n",
    "\n",
    "correspondences_df = pbm3c2_algorithm.compute(\n",
    "    epoch0=epoch0,\n",
    "    epoch1=epoch1,\n",
    "    correspondences_file='epoch_extended_y.csv',\n",
    "    apply_ids=apply_ids,\n",
    "    search_radius=5.0  \n",
    ")\n",
    "\n",
    "print(correspondences_df.head())\n",
    "\n",
    "distances = correspondences_df['distance']\n",
    "uncertainties = correspondences_df['uncertainty']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p4dgeo-doc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
